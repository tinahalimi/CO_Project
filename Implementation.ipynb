{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convex Optimization II - Final Project\n",
        "Tina Halimi 400101078 - Heliya Shakeri 400101391\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2hZNBodtab2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import concurrent\n",
        "from functools import partial\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XE9EEw4yp_6"
      },
      "source": [
        "# Internal Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdLGlkEmsLt6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class InternalDecisionTree:\n",
        "    \"\"\"\n",
        "    A simple decision tree used internally.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, source_desc, classes_):\n",
        "        self.source_desc = source_desc\n",
        "        self.classes_ = classes_\n",
        "\n",
        "        self.feature = None\n",
        "        self.threshold = None\n",
        "        self.children_left = None\n",
        "        self.children_right = None\n",
        "        self.node_prediction = None\n",
        "\n",
        "\n",
        "    def copy_from_dt(self, dt):\n",
        "        self.feature = dt.tree_.feature\n",
        "        self.threshold = dt.tree_.threshold\n",
        "        self.children_left = dt.tree_.children_left\n",
        "        self.children_right = dt.tree_.children_right\n",
        "        self.node_prediction = [dt.classes_[np.argmax(x)] for x in dt.tree_.value]\n",
        "\n",
        "    def copy_from_values(self, feature, threshold, children_left, children_right):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.children_left = children_left\n",
        "        self.children_right = children_right\n",
        "        self.node_prediction = None\n",
        "\n",
        "\n",
        "    def count_training_records(self, x, y):\n",
        "        counts = np.zeros((len(self.feature), len(self.classes_)))\n",
        "\n",
        "        for i in x.index:\n",
        "            y_index = self.classes_.index(y.loc[i])\n",
        "            row = x.loc[i]\n",
        "            cur_node_idx = 0\n",
        "            while self.feature[cur_node_idx] >= 0:\n",
        "                cur_feature_name = x.columns[self.feature[cur_node_idx]]\n",
        "                cur_threshold = self.threshold[cur_node_idx]\n",
        "                if row[cur_feature_name] >= cur_threshold:\n",
        "                    cur_node_idx = self.children_right[cur_node_idx]\n",
        "                else:\n",
        "                    cur_node_idx = self.children_left[cur_node_idx]\n",
        "            counts[cur_node_idx][y_index] += 1\n",
        "\n",
        "        # Prediction for each leaf node\n",
        "        self.node_prediction = [\"\"] * len(self.feature)\n",
        "        for node_idx in range(len(self.feature)):\n",
        "            if self.feature[node_idx] == -2:\n",
        "                self.node_prediction[node_idx] = self.classes_[np.argmax(counts[node_idx])]\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        ret = []\n",
        "        for i in x.index:\n",
        "            row = x.loc[i]\n",
        "            cur_node_idx = 0\n",
        "            while self.feature[cur_node_idx] >= 0:\n",
        "                cur_feature_name = self.feature[cur_node_idx]\n",
        "                cur_threshold = self.threshold[cur_node_idx]\n",
        "                if row[cur_feature_name] >= cur_threshold:\n",
        "                    cur_node_idx = self.children_right[cur_node_idx]\n",
        "                else:\n",
        "                    cur_node_idx = self.children_left[cur_node_idx]\n",
        "\n",
        "            ret.append(self.node_prediction[cur_node_idx])\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "830lt5StyvOy"
      },
      "source": [
        "# Genetic Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tZKWwEmwss9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "class GeneticDecisionTree:\n",
        "\n",
        "    def __init__(self,\n",
        "                 max_depth=4,\n",
        "                 max_iterations=5,\n",
        "                 random_state=0):\n",
        "\n",
        "        self.max_depth = max_depth\n",
        "        self.max_iterations = max_iterations\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.column_names = None\n",
        "        self.classes_ = None\n",
        "        self.internal_dt = None\n",
        "\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        \"\"\"\n",
        "        Create many candidate trees and optionally mutating and\n",
        "        combining these to identify the tree best fit to the training data.\n",
        "        \"\"\"\n",
        "\n",
        "        def get_dt_scores():\n",
        "            return [f1_score(y, idt.predict(x), average='macro') for idt in idt_list]\n",
        "\n",
        "        def combine_trees(parent_a, parent_b):\n",
        "\n",
        "            new_tree = InternalDecisionTree(\n",
        "                parent_a.source_desc + \" & \" + parent_b.source_desc + \" Combined\",\n",
        "                self.classes_,\n",
        "            )\n",
        "\n",
        "            # New tree\n",
        "            feature = [parent_a.feature[0]]\n",
        "            threshold = [(parent_a.threshold[0] + parent_b.threshold[0]) / 2.0]\n",
        "\n",
        "            start_right_tree_parent1 = parent_a.children_right[0]\n",
        "            start_right_tree_parent2 = parent_b.children_right[0]\n",
        "            feature.extend(parent_a.feature[1:start_right_tree_parent1])\n",
        "            threshold.extend(parent_a.threshold[1:start_right_tree_parent1])\n",
        "            children_left = list(parent_a.children_left[:start_right_tree_parent1].copy())\n",
        "            children_right = list(parent_a.children_right[:start_right_tree_parent1].copy())\n",
        "\n",
        "            offset = start_right_tree_parent2 - start_right_tree_parent1\n",
        "            for node_idx in range(start_right_tree_parent2, len(parent_b.children_right)):\n",
        "                feature.append(parent_b.feature[node_idx])\n",
        "                threshold.append(parent_b.threshold[node_idx])\n",
        "                children_left.append(parent_b.children_left[node_idx] - offset)\n",
        "                children_right.append(parent_b.children_right[node_idx] - offset)\n",
        "\n",
        "            new_tree.copy_from_values(feature, threshold, children_left, children_right)\n",
        "            new_tree.count_training_records(x, y)\n",
        "            idt_list.append(new_tree)\n",
        "\n",
        "\n",
        "        x = pd.DataFrame(x)\n",
        "        y = pd.Series(y)\n",
        "        x = x.reset_index(drop=True)\n",
        "        y = y.reset_index(drop=True)\n",
        "\n",
        "        self.column_names = x.columns\n",
        "        self.classes_ = sorted(y.unique())\n",
        "\n",
        "        idt_list = []\n",
        "\n",
        "        # Bootstrap samples of the data\n",
        "        for i in range(10):\n",
        "            x_sample = x.sample(n=len(x))\n",
        "            y_sample = y_sample = y.iloc[x_sample.index]\n",
        "            dt = DecisionTreeClassifier(max_depth=self.max_depth, random_state=self.random_state + i)\n",
        "            dt.fit(x_sample, y_sample)\n",
        "            idt = InternalDecisionTree(\"Original\", self.classes_)\n",
        "            idt.copy_from_dt(dt)\n",
        "            idt_list.append(idt)\n",
        "\n",
        "        idt_scores = get_dt_scores()\n",
        "\n",
        "        for iteration_idx in range(self.max_iterations):\n",
        "            top_scores_idxs = np.argsort(idt_scores)[::-1]\n",
        "\n",
        "            # Mutate\n",
        "            for i in top_scores_idxs[:10]:\n",
        "                parent_idt = idt_list[i]\n",
        "                ret_list = mutate_tree(parent_idt, x, y, self.classes_)\n",
        "                idt_list.extend(ret_list)\n",
        "\n",
        "            # Combine\n",
        "            for i in range(len(top_scores_idxs)):\n",
        "                for j in range(i + 1, len(top_scores_idxs)):\n",
        "                    idt_idx_1 = top_scores_idxs[i]\n",
        "                    idt_idx_2 = top_scores_idxs[j]\n",
        "                    parent_idt_1 = idt_list[idt_idx_1]\n",
        "                    parent_idt_2 = idt_list[idt_idx_2]\n",
        "\n",
        "                    if parent_idt_1.feature[0] == parent_idt_2.feature[0]:\n",
        "                        combine_trees(parent_idt_1, parent_idt_2)\n",
        "                        combine_trees(parent_idt_2, parent_idt_1)\n",
        "\n",
        "            # Generate more random trees\n",
        "            num_random = 100 // (iteration_idx + 1)\n",
        "            for i in range(num_random):\n",
        "                sample_size_log = np.random.uniform(low=7, high=np.log2(len(x) * 2))\n",
        "                sample_size = int(math.pow(2, sample_size_log))\n",
        "                x_sample = x.sample(n=sample_size, replace=True)\n",
        "                y_sample = y.iloc[x_sample.index]\n",
        "                dt = DecisionTreeClassifier(\n",
        "                    max_depth=self.max_depth,\n",
        "                    random_state=self.random_state + iteration_idx + i\n",
        "                )\n",
        "                dt.fit(x_sample, y_sample)\n",
        "                idt = InternalDecisionTree('Random', self.classes_)\n",
        "                idt.copy_from_dt(dt)\n",
        "                idt_list.append(idt)\n",
        "\n",
        "            # Best 20 trees based on scores\n",
        "            idt_scores = get_dt_scores()\n",
        "            top_scores_idxs = np.argsort(idt_scores)[::-1][:20]\n",
        "            idt_list = np.array(idt_list)[top_scores_idxs].tolist()\n",
        "            idt_scores = np.array(idt_scores)[top_scores_idxs].tolist()\n",
        "\n",
        "        top_scores_idxs = np.argsort(idt_scores)[::-1]\n",
        "        idt_list = np.array(idt_list)[top_scores_idxs].tolist()\n",
        "        self.internal_dt = idt_list[0]\n",
        "\n",
        "\n",
        "def mutate_tree(parent_idt, x, y, classes_):\n",
        "    idt_list = []\n",
        "    for j in range(5): # nodes\n",
        "        n_nodes_parent = len(parent_idt.feature)\n",
        "        while True:\n",
        "            node_idx = np.random.choice(n_nodes_parent)\n",
        "            if parent_idt.feature[node_idx] >= 0:\n",
        "                break\n",
        "        feature_idx = parent_idt.feature[node_idx]\n",
        "\n",
        "        for k in range(10):  # threshold\n",
        "            idt = InternalDecisionTree(parent_idt.source_desc + \" - Modified Threshold\", classes_)\n",
        "            new_threshold = parent_idt.threshold.copy()\n",
        "            feat_name = x.columns[feature_idx]\n",
        "            new_threshold[node_idx] = np.random.uniform(low=x[feat_name].min(), high=x[feat_name].max())\n",
        "\n",
        "            idt.copy_from_values(\n",
        "                feature=parent_idt.feature,\n",
        "                threshold=new_threshold,\n",
        "                children_left=parent_idt.children_left,\n",
        "                children_right=parent_idt.children_right\n",
        "            )\n",
        "            idt.count_training_records(x, y)\n",
        "            idt_list.append(idt)\n",
        "    return idt_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfyIsEE1ztNV"
      },
      "source": [
        "# Other Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJzlanWw2R2m"
      },
      "outputs": [],
      "source": [
        "def visualize_tree(genetic_dt):\n",
        "    \"\"\"\n",
        "    Visualizes the trained GeneticDecisionTree by displaying its decision rules.\n",
        "\n",
        "    :param genetic_dt: A trained GeneticDecisionTree instance.\n",
        "    \"\"\"\n",
        "    internal_dt = genetic_dt.internal_dt  # Get the internal tree representation\n",
        "    column_names = genetic_dt.column_names\n",
        "\n",
        "    # Get the depth of each node\n",
        "    depths_arr = [-1] * len(internal_dt.feature)\n",
        "    depths_arr[0] = 0  # Root node starts at depth 0\n",
        "    changed_any = True\n",
        "\n",
        "    while changed_any:\n",
        "        changed_any = False\n",
        "        for i in range(len(depths_arr)):\n",
        "            if depths_arr[i] > -1:\n",
        "                left_child_idx = internal_dt.children_left[i]\n",
        "                right_child_idx = internal_dt.children_right[i]\n",
        "                if (left_child_idx > 0) and (depths_arr[left_child_idx] == -1):\n",
        "                    depths_arr[left_child_idx] = depths_arr[i] + 1\n",
        "                    changed_any = True\n",
        "                if (right_child_idx > 0) and (depths_arr[right_child_idx] == -1):\n",
        "                    depths_arr[right_child_idx] = depths_arr[i] + 1\n",
        "                    changed_any = True\n",
        "\n",
        "    # Generate tree structure\n",
        "    lines_arr = []\n",
        "    for cur_node_idx in range(len(internal_dt.feature)):\n",
        "        indent = \"|   \" * depths_arr[cur_node_idx]  # Indentation for tree levels\n",
        "        if internal_dt.feature[cur_node_idx] >= 0:\n",
        "            feature = internal_dt.feature[cur_node_idx]\n",
        "            threshold = internal_dt.threshold[cur_node_idx]\n",
        "            lines_arr.append(f\"{indent}IF {column_names[feature]} < {threshold:.2f}\")\n",
        "        else:\n",
        "            lines_arr.append(f\"{indent}THEN class = {internal_dt.node_prediction[cur_node_idx]}\")\n",
        "\n",
        "    # Create a map from the node ids to the line ids\n",
        "    node_id_to_line_id_map = {x: x for x in range(len(internal_dt.feature))}\n",
        "\n",
        "    # Create a line for the right side of each condition\n",
        "    for cur_node_idx in range(len(internal_dt.feature) - 1, -1, -1):\n",
        "        if internal_dt.feature[cur_node_idx] >= 0:\n",
        "            indent = \"|   \" * depths_arr[cur_node_idx]\n",
        "            feature = internal_dt.feature[cur_node_idx]\n",
        "            threshold = internal_dt.threshold[cur_node_idx]\n",
        "            node_idx = internal_dt.children_right[cur_node_idx]\n",
        "            lines_idx = node_id_to_line_id_map[node_idx]\n",
        "            lines_arr.insert(lines_idx, f\"{indent}ELSE {column_names[feature]} > {threshold:.2f}\")\n",
        "\n",
        "            # Adjust line mapping for nodes after this insertion\n",
        "            for i in range(node_idx, len(internal_dt.feature)):\n",
        "                node_id_to_line_id_map[i] += 1\n",
        "\n",
        "    # Print the tree structure\n",
        "    for line in lines_arr:\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS0pC5xly4IS"
      },
      "source": [
        "# Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv6OT6p3lhQ-"
      },
      "outputs": [],
      "source": [
        "# Binary Classification Problem\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "np.random.seed(0)\n",
        "data = load_wine()\n",
        "df = pd.DataFrame(data.data)\n",
        "df.columns = data.feature_names\n",
        "y_true = data.target\n",
        "#print(pd.Series(y_true).value_counts())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, y_true, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66zA3g-HzOmm",
        "outputId": "52aaea7a-41f6-4a67-8d46-0df04edbbb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DT: 0.880759176148813\n"
          ]
        }
      ],
      "source": [
        "# Standard Decision Tree\n",
        "clf = DecisionTreeClassifier(max_depth=2)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"DT:\", f1_score(y_test, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asfGcbXpzRZN",
        "outputId": "7c159639-5466-4842-f6b8-c14864ced174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Genetic DT: 0.9799023830031581\n"
          ]
        }
      ],
      "source": [
        "# Genetic Decision Tree\n",
        "np.random.seed(0)\n",
        "gdt = GeneticDecisionTree(max_depth=3, max_iterations=5)\n",
        "gdt.fit(X_train, y_train)\n",
        "y_pred = gdt.internal_dt.predict(X_test)\n",
        "print(\"GDT:\", f1_score(y_test, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kqKcIhN4tV2",
        "outputId": "ac3e72e0-5c9f-4043-8d8c-2f3c34fcadda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IF flavanoids < 1.40\n",
            "|   IF color_intensity < 3.72\n",
            "|   |   THEN class = 1\n",
            "|   ELSE color_intensity > 3.72\n",
            "|   |   THEN class = 2\n",
            "ELSE flavanoids > 1.40\n",
            "|   IF proline < 724.50\n",
            "|   |   THEN class = 1\n",
            "|   ELSE proline > 724.50\n",
            "|   |   THEN class = 0\n"
          ]
        }
      ],
      "source": [
        "visualize_tree(gdt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
